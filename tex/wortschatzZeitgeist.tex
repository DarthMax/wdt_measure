\input{wortschatzZeitgeist-Praeambel.tex}

\begin{document}
\ourtitlepage 
\tableofcontents
\pagenumbering{roman} % Inhaltsverzeichnis roemisch 
\clearpage
\pagenumbering{arabic} % ab jetzt die normale arabische Nummerierung



% EINLEITUNG ###################################################################################
\chapter{Einleitung}

%##########################################
\section{Aufgabenstellung}
Das Portal  \emph{Wörter des Tages}\footnote{\url{http://wortschatz.uni-leipzig.de/wort-des-tages}, Abgerufen am 29.10.2015,~9:34~Uhr} stellt eine Übersicht von Wörtern, die an einem ausgewählten Tag besonders relevant erschienen dar. Die Wörter sind in neun Kategorien eingeordnet. Nach der Beschreibung auf der Website werden die Wörter ermittelt in dem die tagesaktuelle Häufigkeit eines Wortes mit seiner durchschnittlichen Häufigkeit über längere Zeit hinweg gemessen wird.\\
Die Aufgabe dieser Arbeit ist es verschiedene Möglichkeiten der Bestimmung von Wörtern, die an einem gewählten Tag von besonderer Relevanz sind zu beschreiben, zu vergleichen und zu evaluieren. 
Die Datengrundlage zur Erstellung der Wörter des Tages ist ein Corpus, das durch tägliches crawlen von Newsseiten generiert wird. Die Quellen der Newseiten sind eine definierte Menge an für relevant erachtete Seiten mit Nachrichten wie zum Beispiel \emph{Spiegel.de}.\\
Bei allen Ansätzen, die auf das Vorkommen in einem Referenzzeitraum rekurrieren besteht das Korpus aus allen gecrawlten Newsseiten des voragngegangenen Jahres (2014).
Als Zusatzaufgabe soll ein musterbasiertes Verfahren in SQL entworfen werden, das es ermöglicht aufgrund eines gewählten Verfahrens falsch identifizierte Wörter zu filtern. Ein Beispiel hierfür sind Datumsangaben, die als relevant erscheinen, da sie Tagesaktuell oft auftauchen, aber im Vergleichszeitraum selten.

%##########################################
\section{Vergleichbare Ansätze}
Das Problem der Trenderkennung ist ein vielfältiges Problem mit einer großen Bandbreite an Anwendungsgebieten. Eine der vielleicht populärsten Anwendungen ist die Erkennung von Trendbegriffen bei Twitter, einem Microbloging-Dienst mehreren hundert Millionen Nutzern und 500 Mio Tweets täglich. Aufgrund dieser immensen Vielfalt an Nutzern und Nachrichten ist es möglich, dass hochaktuelle Nachrichten und Neuigkeiten rasend schnell global verbreitet werden können. Mithilfe von Trendanalyse ist es möglich globale aber auch lokale Entwicklungen zeitig zu erfassen und zu analysieren.
Einen ähnlichen Ansatz verfolgt das Google Projekt \emph{Google Trends}. Hier werden die Suchenanfragen der weltweit größten Websuchmaschine ausgewertet, wodurch die zeitabhängige Auswertung einzelner Suchbegriffe möglich wird. \\
Aber auch bei kleinerer Datenmengen ist das Erkennen von Trends bzw. Anomalien nützlich. Angewand auf Logdateien ist es so zum Beispiel möglich Angriffe auf ein Computersystem zu erkennen. \cite{Zwietasch14}


% HAUPTTEIL THEORIE ##########################################################################
%\chapter{Methoden zum Finden tagesaktueller Wörter}

%##########################################
\chapter{Maße zur Trend-Detection}
Im folgenden Abschnitt werden fünf Methoden vorgestellt, die f\"uer jedes Wort eines Tageskorpus eine Ma\ss zahl bestimmen, die die Relevanz des Wortes an diesem Tag ausdr\"ucken soll.

%#####################
\input{parts/poisson_etc.tex}

%#####################
\input{parts/z_score.tex}

%#####################
%\subsection{Weitere Maße}
%Einbeziehung der Anzahl von Quelle

%##########################################
\chapter{Zeitreihenanalysen}
Es wurde eine Pipeline in R geschrieben um geglättete Tagesfrequenzen zu berechnen.\footnote{Dieser Teil des Projektes wurde von Thomas Döring verfasst, der leider zum Zeitpunkt der Fertigstellung dieser Arbeit nicht mehr auf Kommunikationsversuche antwortete.} Diese Pipeline umfasst sechs Teile. Die Programmteile sind unter thomas/v2/R/1.r~-~6.r im Projektordner zu finden.
\begin{enumerate}
\item Aufbau einer Verbindung mit der Datenbank
\item Laden der Daten aus der Datenbank
\item Reshape der Daten I: Eine Spalte entspricht einem Wort
\item Berechnung der neuen Werte mittels Filter
\item Reshape der Daten II: Umformung in die Ursprüngliche Form mit einem Wort pro Zeile (melt)
\item Schreiben der berechneten Daten in die Datenbank 
\end{enumerate}
Die Abbildung~\ref{pic.time_airplane} stellt beispielhaft die Ergebnisse für das Wort Flugzeug dar. Mit der genutzten Bibliothek kann leicht durch Parameter die größe des Fensters angepasst werden.\footnote{Verwendete Funktion in R dokumentiert in: \url{https://stat.ethz.ch/R-manual/R-devel/library/stats/html/filter.html}, Abgerufen am 30.10.2015, 18:55 Uhr.}
% Hier Beispiel Flugzeug
\begin{figure}[h!]
    \centering
    \includegraphics[width=0.82\textwidth]{pictures/timeflugzeug.png}
    \caption{Illustration des gleitenden Fensters anhand des Wortes Flugzeug. Die rote Linie stellt die berechneten Werte dar. Die größe des Zeitfensters zur Durchschnittsbildung konnte leider nicht rekonstruiert werden (Annahme 8, da die ersten 7 Tage nicht geplottet sind). }\label{pic.time_airplane}
\end{figure}

 
%\chapter{Cleaning}

%##########################################
%\chapter{Cleaning}
%Es sollen Datumsangaben und evtl.\ neu auftauchende strukturelle Angaben ausgefiltert werden.\\
%Ansatz: Regelbasiert.\\
%Gibt es Maße, die solche Angaben strukturell ausschließen?



%HAUPTTEIL IMPLEMENTIERUNG ##################################################################
%\chapter{Implementierungen in SQL und R}



% AUSWERTUNG #################################################################################
\chapter{Ein empirischer Vergleich}
 
Kriterien: Anteil niederfrequenter Wörter in der Top-Liste\\
\section{Einleitung}
Die Messung der G\"ute der Ergebnisse stellt eine Herausforderung dar, da es keine geeignete Referenz, beispielswiese in Form eines Goldstandards der wichtigsten Worte eines Tages gibt. Um die G\'ute trotzdem einsch\"atzen zu k\"onnen bieten sich zwei herangehensweisen an. Zum einen die eigenst\"andige manuelle Pr\"ufung der Ergebnisse unter selbst formulierten Kriterien, zum anderen der quantitative Vergleich mittels eines geeigneten Abstandsma\ss es. Letzterer Ansatz bietet aber nur die M\"oglichkeit eines Verlgeiches der \"Ahnlichkeiten der Ergebnisse und hilft abzusch\"atzen wie sich die Ergebnisse gegeneinander verhalten. \"Uber die G\"ute gibt diese Methode keine Auskunft. Allerdings lassen sich Ausrei\ss er gut erkennen und der Pr\"amisse, dass gleiche Ergebnisse, die aus verschiedenen M\"ass ungen stammen eine h\"ohere Wahrscheinlichkeit besitzen gute Ergebnisse zu sein l\"asst sich auch die Qualit\"at beurteilen.
\section{Qualitativer Vergleich}
Um sich einen Eindruck der Ergebnisse anhand der resultierenden soriterten Wortlisten zu verschaffen wurden die Listen ausgew\"ahlter Tage verglichen. Da die Untersuchenden keine ausgewiesene Expertiese ausweist, die wichtigsten W\"orter eines t\"aglichen Nachrichtenstroms zu indentifizieren, die \"uber der eines Zeitungslesers liegt kann die Analyse nicht in die Tiefe gehen. Aber durch die Wahl der Tage l\"asst sich das \"Uberblicken der Ergebnisse vereinfachen. Deshalb w\"ahlten wir den 1.1.2015. \\
 Das funktiuoniert so noch nicht!!! Umschreiben ist nur blabla!!
\section{Quantitativer Vergleich - Average Overlap als Vergleichma\ss}
\input{parts/average_overlap.tex}



% SCHLUSS #####################################################################################
\chapter{Bewertung und Zusammenfassung}



% LITERATUR ####################################################################################
\nocite{*}%alle nicht aufgeführte Literatur auch auffuehren
\bibliographystyle{plaindin} %alphadin_martin
\bibliography{wortschatzZeitgeistLit} 

\end{document}
