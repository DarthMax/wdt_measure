\input{wortschatzZeitgeist-Praeambel.tex}

\begin{document}
\ourtitlepage 
\tableofcontents
\clearpage
\pagenumbering{arabic} % ab jetzt die normale arabische Nummerierung
\chapter{Einleitung}
\section{Aufgabenstellung}
Es soll untersucht werden, welche Maße sinnvoll für die Generierung der Wörter des Tages sind. Eine Implementierung soll in SQL und für Zeitreihenuntersuchungen in R erfolgen.\\
Desweiteren soll ein regelbasiertes Verfahren implementiert werden um Datumsangaben und andere strukturelle Worte zu filtern.\\
\section{Status quo}
\section{Vergleichbare Ansätze}
Tagesaktuelle Wikiartikel\\
google trends?\\


\chapter{Das finden von Tagesaktuellen Wörter}
\section{Maße zur Trend-Detection}
\subsection{Relatives Vorkommen (Referenz)}
Das Maß wird durch die Differenz des relativen Anteils eines Tokens an allen Tokens eines Tages und dem relativen Anteil eines Tokens an allen Tokens eines Vergleichskorpus bestimmt. 
\begin{equation}
sig_{referenz}(w) = p_{tag} - p_{jahr}
\end{equation}

\subsection{Poisson-Maß}

Die Formel leitet sich aus der Poissonverteilung ab und beschreibt wie Wahrscheinlich es ist, dass die gemessene Tagesfrequenz beobachtet werden kann. 
\begin{equation}
sig_{poisson}(w) = \frac{k(\log(k)-\log(n\cdot p) -1 ))}{\log(n)}
\end{equation}
k:= Anzahl der Token von w in Tagesbericht\\
n := Anzahl der Tokens in Tagesbericht\\
p := relativer Anteil eines Tokens am Jahreskorpus\\
Es ist das gleiche Maß wie in \cite[S. 338-340]{heyer06} beschrieben und hergeleitet. Hier aber nicht zum auffinden von signifikanten Kookurenzen, sondern zum auffinden von signifikanten Nennungen im Tageskorpus gegenüber einem Vergleichskorpus.\\

\subsection{Termfrequenz inverse Dokumentenfrequenz (tf-idf)}
 \begin{equation}
sig_{tf idf}(w) = \frac{k}{\max(K)} \cdot \log ( \frac{365}{|documentdays(w)|})
\end{equation}

\subsection{Z-Score}
Benattar et al. beschreiben in \cite{benattar2011trend} einen Ansatz zur Trend-Erkennung basierend auf dem Z-Score. Dabei beziehen Sie neben der relativen Worthäufigkeit noch die Anzahl der Tage ein an denen ein Wort mindestens einmal auftritt, um so das 0-Frequenz-Problem zu umgehen.

\subsubsection{Berechnung}
\begin{itemize}
	\item{Wortfrequenz}\\
		$f(w)_d :=$ Anzahl der Vorkommen von Wort $w$ an Datum $d$
	\item{relative Worthäufigkeit}\\
		Die relative Worthäufigkeit $p(w)_d$ berechnet sich durch: \\
		$t_d :=$ Anzahl verschiedener Worte an Datum $d$
		$$ p(w)_d = \frac{f(w)_d}{t_d} \\ $$
	\item{Erwartungswert}\\
		Der Erwartungswert $\bar{w}$ berechnet sich durch: \\
		$N:=$ Anzahl der Tage in der betrachteten Zeitspanne
		$$\bar{w}=\frac{1}{N} \sum p(w)_d$$
	\item{Standartabweichung}\\
		Die Standartabweichung $\sigma_w$ berechnet sich durch:
		$$\sigma_w = \sqrt{\frac{1}{N} \sum (p(w)_d - \bar{w}^2}$$
	\item{ZScore}\\
		Der Zscore $Z(w)_d$ misst die Abweichung der relativen Worthäufigkeit vom Erwartungswert in Vielfachen der Standartabweichung.
		$$Z(w)_d= \frac{p(w)_d - \bar{w}}{\sigma_w}$$		
	\item{Auftrittshäufigkeit}\\
		Die Auftrittshäufigkeit $Po(w)$ gibt an wie vielen Tagen innerhalb des betrachteten Zeitraums das Wort mindestens einmal auftritt:\\
		$nbD(w) :=$ Anzahl der Tage an denen $w$ vorkommt//
		$c_d:=$ Anzahl der Tage innerhalb des betrachteten Zeitraums
		$$Po(w)=\frac{nbD(w}{c_d}$$
	\item{Schwellwerte}
		Zur besseren Unterscheidung echter Trends von statistischen Anomalien schlagen Benattar et. al. vor die Worte anhand ihrer Auftrittshäufigkeit zu clustern. Den Clustern werden dabei Z-Score-Schwellwerte zugeordnet. Überschreitet der Z-Score eines Wortes den Schwellwert seines Clusters wird dieses Wort als signifikant und somit als Trend eingestuft. Cluster mit niedriger Auftrittshäufigkeit erhalten dabei höhere Schwellwerte. Je häufiger ein Wort auftritt desto niedriger wird der Schwellwert. 
		
		
\end{itemize}

\subsubsection{Vorgehen}
\begin{enumerate}
	\item Für jedes Wort in $w$ in $d$ berechne $Z(w)$
	\item 
\end{enumerate}




\subsection{Weitere Maße}
Einbeziehung der Anzahl von Quellen.
\subsection{Bewertung der Ma\ss e}
Kriterien: Anteil niederfrequenter Wörter in der Top-Liste\\

\section{Zeitreihenanalysen}
\section{Cleaning}
Es sollen Datumsangaben und evtl. neu auftauchende strukturelle Angaben ausgefiltert werden.\\
Ansatz: Regelbasiert.\\
Gibt es Maße, die solche Angaben strukturell ausschließen?


\chapter{Implementierungen in SQL und R}
\chapter{Ein empirischer Vergleich}

\chapter{Bewertung und Zusammenfassung}











 
\nocite{*}%alle nicht aufgeführte Literatur auch auffuehren
\bibliographystyle{plaindin} %alphadin_martin
\bibliography{wortschatzZeitgeistLit} 


\end{document}